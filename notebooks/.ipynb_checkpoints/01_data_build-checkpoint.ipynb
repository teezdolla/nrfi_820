{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d3c770-611c-46da-8a38-3b815ab50c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 01_data_build ===\n",
      "Python 3.12.7 | pandas 2.3.1 | numpy 2.2.6 | sklearn 1.7.1 | xgboost 3.0.4\n",
      "Platform: Windows 11 | Time: 2025-08-21 19:17:33\n",
      "Project root: C:\\Users\\alex\\Desktop\\nrfi\n"
     ]
    }
   ],
   "source": [
    "# Universal header: robust project root (works from repo root OR notebooks/)\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "def _find_root():\n",
    "    cwd = Path.cwd()\n",
    "    for p in [cwd] + list(cwd.parents):\n",
    "        if (p / \"src\").is_dir() and (p / \"configs\").is_dir():\n",
    "            return p\n",
    "    return cwd\n",
    "\n",
    "PROJECT_ROOT = _find_root().resolve()\n",
    "os.environ[\"NRFI_PROJECT_ROOT\"] = str(PROJECT_ROOT)\n",
    "if str(PROJECT_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "from utils import print_run_header, set_seed\n",
    "print_run_header(\"01_data_build\")\n",
    "set_seed(42)\n",
    "print(\"Project root:\", PROJECT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7611ac92-f34f-41de-9924-b9b481a8c97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded: 2021-04-01 → 2024-05-15\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "CONFIG_PATH = PROJECT_ROOT / \"configs\" / \"config.yaml\"\n",
    "CONFIG_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not CONFIG_PATH.exists():\n",
    "    # Write a default config so first run never fails\n",
    "    CONFIG_DEFAULT = \"\"\"project:\n",
    "  name: nrfi_yrfi\n",
    "  seed: 42\n",
    "  use_duckdb: true\n",
    "  log_level: INFO\n",
    "  time_zone_default: America/New_York\n",
    "paths:\n",
    "  data_dir: data\n",
    "  raw_dir: data/raw\n",
    "  processed_dir: data/processed\n",
    "  reference_dir: data/reference\n",
    "  sample_dir: data/sample\n",
    "  outputs_dir: outputs\n",
    "  reports_dir: reports\n",
    "  odds_dir: data/odds\n",
    "training:\n",
    "  start_date: \"2024-04-01\"\n",
    "  end_date: \"2024-05-15\"\n",
    "  min_games_required: 10\n",
    "  n_folds: 3\n",
    "  fold_granularity: \"M\"\n",
    "model:\n",
    "  use_xgb: true\n",
    "  xgb_params:\n",
    "    n_estimators: 200\n",
    "    max_depth: 3\n",
    "    learning_rate: 0.08\n",
    "    subsample: 0.9\n",
    "    colsample_bytree: 0.9\n",
    "    reg_lambda: 1.0\n",
    "    reg_alpha: 0.0\n",
    "    n_jobs: -1\n",
    "  calibration: \"isotonic\"\n",
    "  bootstrap:\n",
    "    enabled: true\n",
    "    n_boot: 200\n",
    "    block_unit: \"D\"\n",
    "    block_size: 3\n",
    "features:\n",
    "  lineup_samples: 25\n",
    "  min_history_days: 14\n",
    "  eb_prior_strength: 50\n",
    "  default_first_pitch_local_time: \"19:00\"\n",
    "odds:\n",
    "  kelly_fraction_cap: 0.25\n",
    "  min_edge_abs: 0.02\n",
    "  min_ci_half_width: 0.06\n",
    "backtest:\n",
    "  bankroll_start: 1000\n",
    "  flat_stake: 10.0\n",
    "\"\"\"\n",
    "    CONFIG_PATH.write_text(CONFIG_DEFAULT)\n",
    "\n",
    "cfg = yaml.safe_load(CONFIG_PATH.read_text())\n",
    "print(\"Config loaded:\", cfg[\"training\"][\"start_date\"], \"→\", cfg[\"training\"][\"end_date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee16e0e-4b2c-4194-b93a-9fe4715001cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pybaseball.statcast 2021-04-01..2024-05-15] start\n",
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n",
      "Skipping offseason dates\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 783/783 [07:35<00:00,  1.72it/s]\n",
      "C:\\Users\\alex\\Desktop\\nrfi\\.venv\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pybaseball.statcast 2021-04-01..2024-05-15] done in 574.66s\n",
      "PBP shape: (2491869, 120)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Statcast / PBP pulls with caching + fallback sample\n",
    "from data import DataManager, fetch_statcast_range\n",
    "\n",
    "dm = DataManager.from_config(cfg)\n",
    "dm.ensure_dirs()\n",
    "\n",
    "pbp = fetch_statcast_range(\n",
    "    start_date=cfg[\"training\"][\"start_date\"],\n",
    "    end_date=cfg[\"training\"][\"end_date\"]\n",
    ")\n",
    "\n",
    "print(\"PBP shape:\", pbp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "672b58c9-c98b-4a8e-8741-53f4e0840d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alex\\Desktop\\nrfi\\src\\data.py:145: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  r = df1.groupby(\"game_pk\").apply(_runs_in_inning).rename(\"first_inning_runs\").reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date            game_id  game_pk         game_datetime_utc away_team  \\\n",
      "0 2021-04-10  2021-04-10_COL_SF   632169 2021-04-10 00:00:00+00:00       COL   \n",
      "1 2021-04-11  2021-04-11_KC_CWS   632170 2021-04-11 00:00:00+00:00        KC   \n",
      "2 2021-04-11  2021-04-11_COL_SF   632188 2021-04-11 00:00:00+00:00       COL   \n",
      "\n",
      "  home_team  yrfi  \n",
      "0        SF     0  \n",
      "1       CWS     0  \n",
      "2        SF     1  \n"
     ]
    }
   ],
   "source": [
    "from data import build_first_inning_labels\n",
    "labels = build_first_inning_labels(pbp)\n",
    "print(labels.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f3fd4a6-b0fc-457d-b7a1-4415d24b5e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing game_datetime_utc: 0 / 8680\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "      <th>game_datetime_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-10</td>\n",
       "      <td>SF</td>\n",
       "      <td>COL</td>\n",
       "      <td>2021-04-11 02:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-11</td>\n",
       "      <td>CWS</td>\n",
       "      <td>KC</td>\n",
       "      <td>2021-04-11 19:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-11</td>\n",
       "      <td>SF</td>\n",
       "      <td>COL</td>\n",
       "      <td>2021-04-12 02:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-13</td>\n",
       "      <td>NYM</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2021-04-13 23:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-13</td>\n",
       "      <td>MIN</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2021-04-14 00:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date home_team away_team         game_datetime_utc\n",
       "0 2021-04-10        SF       COL 2021-04-11 02:00:00+00:00\n",
       "1 2021-04-11       CWS        KC 2021-04-11 19:00:00+00:00\n",
       "2 2021-04-11        SF       COL 2021-04-12 02:00:00+00:00\n",
       "3 2021-04-13       NYM       PHI 2021-04-13 23:00:00+00:00\n",
       "4 2021-04-13       MIN       BOS 2021-04-14 00:00:00+00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Robust first-pitch time attachment (offline path, no schedule fetch needed) ---\n",
    "# Computes game_datetime_utc from labels[date] + default_local_time localized by home_team's timezone.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 0) Inputs this relies on:\n",
    "# - labels: DataFrame with at least [\"game_id\", \"date\", \"home_team\", \"away_team\"]\n",
    "# - cfg[\"features\"][\"default_first_pitch_local_time\"]: e.g. \"19:05\"\n",
    "# - dm.reference_dir: directory used by ensure_stadium_reference\n",
    "# - data.ensure_stadium_reference: returns stadiums ref with [\"team_code\",\"timezone\"]\n",
    "\n",
    "# 1) Stadium/timezone reference\n",
    "stadiums = data.ensure_stadium_reference(dm.reference_dir)\n",
    "\n",
    "# 2) Ensure required columns exist\n",
    "required = {\"date\", \"home_team\"}\n",
    "missing = required - set(labels.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"labels is missing required columns: {sorted(missing)}\")\n",
    "\n",
    "# 3) Normalize/guard types\n",
    "labels = labels.copy()\n",
    "labels[\"date\"] = pd.to_datetime(labels[\"date\"])\n",
    "\n",
    "# 4) Map each home team to its IANA timezone (fallback to UTC)\n",
    "tz_map = stadiums.set_index(\"team_code\")[\"timezone\"].to_dict()\n",
    "tz_series = labels[\"home_team\"].map(tz_map).fillna(\"UTC\")\n",
    "\n",
    "# 5) Build naive local datetimes from date + default local first pitch time (string like \"19:05\")\n",
    "default_local_time = cfg[\"features\"][\"default_first_pitch_local_time\"]\n",
    "local_str = labels[\"date\"].dt.strftime(\"%Y-%m-%d\") + \" \" + str(default_local_time)\n",
    "local_naive = pd.to_datetime(local_str)\n",
    "\n",
    "# 6) Row-wise tz-localize by grouping on timezone to keep it vectorized-per-group\n",
    "utc_series = pd.Series(pd.NaT, index=labels.index, dtype=\"datetime64[ns, UTC]\")\n",
    "\n",
    "for tz, idx in tz_series.groupby(tz_series).groups.items():\n",
    "    # idx is an index list for rows sharing the same timezone\n",
    "    try:\n",
    "        localized = local_naive.loc[idx].dt.tz_localize(tz, nonexistent=\"NaT\", ambiguous=\"NaT\")\n",
    "        utc_series.loc[idx] = localized.dt.tz_convert(\"UTC\")\n",
    "    except Exception as e:\n",
    "        # If a bad tz somehow slips in, fall back to UTC for those rows\n",
    "        localized = local_naive.loc[idx].dt.tz_localize(\"UTC\", nonexistent=\"NaT\", ambiguous=\"NaT\")\n",
    "        utc_series.loc[idx] = localized  # already UTC\n",
    "\n",
    "# 7) Write/merge into labels\n",
    "if \"game_datetime_utc\" in labels.columns:\n",
    "    # keep any existing non-null values, fill the rest with our computed UTC times\n",
    "    labels[\"game_datetime_utc\"] = labels[\"game_datetime_utc\"].combine_first(utc_series)\n",
    "else:\n",
    "    labels[\"game_datetime_utc\"] = utc_series\n",
    "\n",
    "# 8) Quick sanity\n",
    "n_missing = int(labels[\"game_datetime_utc\"].isna().sum())\n",
    "print(f\"missing game_datetime_utc: {n_missing} / {len(labels)}\")\n",
    "\n",
    "# 9) Preview a few rows\n",
    "cols = [c for c in [\"date\",\"home_team\",\"away_team\",\"game_datetime_utc\"] if c in labels.columns]\n",
    "try:\n",
    "    display(labels.head(5)[cols])\n",
    "except Exception:\n",
    "    print(labels.head(5)[cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c70a7c4-ed0c-4c03-b1cf-9552b47b1150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "  team_code  season  park_factor_runs\n",
      "0       NYY    2023              1.03\n",
      "1       BOS    2023              1.05\n",
      "2       LAD    2023              0.96\n"
     ]
    }
   ],
   "source": [
    "# Park factors (recompute if missing)\n",
    "from data import ensure_park_factors\n",
    "park = ensure_park_factors(dm.reference_dir, pbp=pbp, seasons=[2023])\n",
    "print(park.shape)\n",
    "print(park.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b43b46ad-da65-4878-96bd-a9ecd8f479dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather placeholder rows: (8680, 5)\n"
     ]
    }
   ],
   "source": [
    "# Weather (meteostat) with robust fallbacks Skip for now\n",
    "import pandas as pd\n",
    "\n",
    "# Skip weather for now – create neutral placeholder\n",
    "weather = pd.DataFrame({\n",
    "    \"game_id\": labels[\"game_id\"],\n",
    "    \"temp_c\": 20.0,\n",
    "    \"rel_humidity\": 50.0,\n",
    "    \"wind_kph\": 8.0,\n",
    "    \"mslp_hpa\": 1015.0\n",
    "})\n",
    "print(\"Weather placeholder rows:\", weather.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7f64037-8809-44be-a021-5ba617d26073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample written -> C:\\Users\\alex\\Desktop\\nrfi\\data\\sample\n"
     ]
    }
   ],
   "source": [
    "# Persist a tiny, offline sample\n",
    "from data import write_sample_bundle\n",
    "write_sample_bundle(dm.sample_dir, labels=labels, pbp=pbp, stadiums=stadiums, weather=weather)\n",
    "print(\"Sample written ->\", dm.sample_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2489b29-98cf-4263-8b99-62858a86f5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\alex\\Desktop\\nrfi\\data\\processed\\labels.parquet\n",
      "01_data_build ✅\n"
     ]
    }
   ],
   "source": [
    "# Save labels to processed\n",
    "from utils import write_parquet\n",
    "proc_path = PROJECT_ROOT / cfg[\"paths\"][\"processed_dir\"]\n",
    "proc_path.mkdir(parents=True, exist_ok=True)\n",
    "write_parquet(labels, proc_path / \"labels.parquet\")\n",
    "print(\"Saved:\", proc_path / \"labels.parquet\")\n",
    "print(\"01_data_build ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1535cf5-d947-4c4f-becd-608bd1ea7f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504cd2c-1487-4d1f-a706-575283fce954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (nrfi)",
   "language": "python",
   "name": "nrfi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
